{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0fb552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9f988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f78052a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Andy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935579a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "303d58f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\andy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (10.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c44d53e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "img = Image.open('./targets/img_001.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa63d5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "img = transform(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "125ad5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_img = torch.unsqueeze(img, 0)\n",
    "batch_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51cf5492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.4830e-03, 2.6604e-04, 3.0629e-05, 2.7270e-05, 7.8573e-05, 1.2216e-04,\n",
       "        3.3358e-06, 8.5931e-05, 1.2538e-05, 9.9714e-07, 1.5659e-05, 2.1457e-05,\n",
       "        2.5498e-05, 1.7559e-06, 1.5591e-05, 1.4726e-05, 1.5181e-05, 1.3390e-04,\n",
       "        1.2088e-05, 4.4910e-05, 3.5022e-05, 8.5771e-05, 1.2370e-05, 8.6282e-06,\n",
       "        1.4956e-05, 4.2844e-05, 3.4301e-05, 1.2191e-05, 5.9189e-05, 3.8683e-05,\n",
       "        5.3345e-06, 2.4622e-06, 2.4101e-06, 4.8767e-05, 2.0202e-03, 7.1393e-05,\n",
       "        4.3111e-04, 1.5294e-05, 1.6270e-04, 9.1905e-06, 1.8581e-05, 5.8189e-05,\n",
       "        1.1967e-04, 1.5076e-05, 6.2325e-05, 4.2843e-05, 1.1190e-05, 5.3531e-05,\n",
       "        6.4427e-06, 4.7836e-06, 6.8742e-05, 3.4553e-04, 1.1282e-04, 3.4778e-05,\n",
       "        3.0730e-05, 5.2000e-06, 3.9066e-05, 5.1234e-06, 2.7469e-05, 2.2619e-05,\n",
       "        4.5393e-05, 3.0120e-05, 7.4271e-05, 7.6366e-05, 1.0065e-05, 3.9847e-05,\n",
       "        4.2859e-05, 3.7422e-06, 4.8629e-05, 3.4250e-05, 7.2366e-07, 2.9299e-04,\n",
       "        2.1031e-06, 1.2879e-05, 2.2002e-06, 1.8620e-05, 2.0755e-05, 1.0299e-05,\n",
       "        7.6380e-05, 4.5696e-05, 1.1878e-04, 6.5877e-06, 3.8880e-05, 1.1017e-04,\n",
       "        1.7556e-05, 9.2262e-06, 3.6959e-05, 9.3979e-05, 9.9858e-04, 2.1417e-05,\n",
       "        5.2555e-05, 6.5169e-05, 1.0808e-04, 9.3603e-05, 1.4489e-04, 2.5587e-05,\n",
       "        9.2895e-05, 3.1384e-04, 2.3506e-05, 4.1505e-05, 4.0735e-05, 2.4477e-05,\n",
       "        1.0368e-05, 7.0565e-04, 1.2875e-05, 8.7746e-07, 4.1882e-06, 2.2899e-05,\n",
       "        1.7816e-05, 2.6902e-05, 1.0590e-04, 1.2806e-04, 9.1076e-05, 1.6324e-04,\n",
       "        4.7197e-04, 1.7159e-04, 2.5649e-04, 9.2910e-05, 3.0815e-05, 6.4106e-05,\n",
       "        4.6745e-05, 2.4566e-05, 2.2238e-04, 2.7357e-05, 6.6641e-04, 9.8120e-06,\n",
       "        4.2124e-05, 8.7971e-06, 9.0063e-05, 1.9827e-04, 5.5234e-05, 2.4295e-05,\n",
       "        4.1173e-06, 1.8587e-05, 1.1003e-05, 4.7166e-06, 5.1613e-05, 3.6180e-06,\n",
       "        1.9529e-06, 3.3237e-06, 1.5449e-05, 1.8832e-05, 2.2002e-06, 6.1935e-05,\n",
       "        9.5052e-06, 1.0486e-04, 2.5683e-05, 2.0043e-04, 2.4737e-04, 2.7648e-05,\n",
       "        1.6209e-04, 3.2162e-04, 2.6291e-05, 1.9838e-05, 1.1749e-05, 7.7441e-05,\n",
       "        3.8844e-05, 1.2761e-04, 2.0969e-04, 5.0401e-05, 9.2493e-05, 5.2614e-05,\n",
       "        1.9734e-05, 4.6536e-05, 1.3405e-05, 2.5501e-05, 1.3009e-05, 2.9411e-05,\n",
       "        5.3294e-05, 6.4582e-05, 2.0968e-05, 3.6629e-05, 5.0415e-05, 2.5237e-04,\n",
       "        4.4927e-05, 2.0696e-05, 3.0611e-04, 3.7633e-05, 3.2999e-05, 8.4377e-06,\n",
       "        3.4788e-06, 3.0460e-05, 2.2215e-05, 2.7630e-05, 3.9457e-05, 1.3775e-04,\n",
       "        9.7022e-05, 9.8693e-05, 5.1734e-05, 7.5563e-05, 6.5497e-05, 2.5111e-05,\n",
       "        4.6694e-05, 1.0027e-04, 1.2479e-05, 3.0293e-04, 6.3327e-05, 5.2837e-05,\n",
       "        7.3274e-05, 8.7868e-04, 6.8644e-06, 9.2662e-05, 1.0612e-05, 1.2305e-04,\n",
       "        4.3834e-05, 3.4239e-04, 1.6456e-04, 1.7315e-04, 1.7484e-04, 4.8946e-05,\n",
       "        8.6402e-05, 1.3810e-04, 3.4465e-05, 1.0841e-04, 9.4455e-05, 1.3432e-04,\n",
       "        1.7274e-04, 2.8729e-05, 2.5722e-04, 4.6559e-05, 2.2660e-04, 3.9453e-05,\n",
       "        3.7475e-05, 8.3167e-05, 1.5747e-04, 1.4890e-04, 1.7741e-04, 1.5578e-04,\n",
       "        9.8301e-06, 1.3542e-05, 1.1959e-05, 4.2762e-05, 7.2203e-05, 1.2384e-05,\n",
       "        1.5412e-05, 5.9596e-04, 4.3389e-05, 6.4571e-05, 1.0159e-05, 2.0831e-05,\n",
       "        5.0578e-05, 9.9039e-06, 5.7538e-06, 1.8893e-05, 2.9025e-05, 1.8266e-04,\n",
       "        2.6092e-05, 4.9708e-05, 4.7050e-05, 3.3591e-05, 6.7194e-05, 2.3717e-05,\n",
       "        4.8228e-05, 1.3317e-04, 5.8636e-05, 1.8628e-05, 7.0529e-05, 3.4914e-05,\n",
       "        1.1397e-05, 1.4730e-05, 7.8535e-06, 1.2952e-05, 6.6748e-05, 2.3552e-04,\n",
       "        1.4442e-04, 1.1838e-05, 2.9139e-05, 2.1213e-05, 1.6670e-04, 1.1632e-05,\n",
       "        2.1673e-05, 4.9782e-05, 3.0535e-05, 4.0763e-05, 1.5901e-05, 1.4617e-05,\n",
       "        4.7293e-06, 3.3314e-05, 9.9001e-06, 9.5749e-06, 7.8813e-05, 1.8805e-04,\n",
       "        4.3566e-05, 8.0083e-05, 1.2911e-04, 1.8774e-04, 1.7700e-05, 1.0113e-05,\n",
       "        1.6836e-05, 1.7639e-06, 5.5253e-06, 7.6339e-06, 1.5139e-05, 7.5571e-06,\n",
       "        1.7132e-06, 7.9583e-06, 6.9981e-06, 5.2277e-07, 6.6368e-06, 8.8678e-06,\n",
       "        7.6318e-05, 9.1544e-06, 4.1121e-04, 1.0262e-04, 7.6512e-06, 1.0861e-05,\n",
       "        5.4479e-04, 6.1872e-06, 4.6200e-05, 9.1855e-06, 4.1481e-05, 8.9212e-06,\n",
       "        2.0778e-05, 9.8848e-06, 1.2937e-04, 2.0762e-05, 9.9776e-06, 2.9689e-04,\n",
       "        2.5580e-05, 7.7951e-04, 3.3329e-04, 7.3840e-06, 1.2569e-05, 1.5044e-05,\n",
       "        1.1186e-05, 2.6087e-05, 2.0086e-04, 4.1837e-04, 2.4620e-05, 6.8026e-05,\n",
       "        2.3209e-05, 4.4442e-05, 3.6247e-05, 1.4481e-05, 6.3313e-06, 2.1871e-06,\n",
       "        6.3748e-07, 3.5755e-05, 6.5828e-06, 8.5180e-05, 2.3850e-04, 3.1867e-05,\n",
       "        7.5212e-06, 1.9161e-05, 1.2405e-05, 5.3270e-06, 8.8269e-06, 1.7994e-06,\n",
       "        1.1460e-05, 4.0347e-06, 2.8127e-06, 3.0601e-05, 1.9019e-05, 2.7176e-05,\n",
       "        6.6289e-06, 2.6428e-05, 9.6756e-05, 6.7074e-05, 6.2561e-05, 5.0183e-05,\n",
       "        3.6466e-05, 8.6584e-05, 1.5560e-05, 1.5765e-04, 1.6841e-05, 3.3077e-05,\n",
       "        1.6075e-06, 7.1832e-06, 6.4836e-06, 7.9359e-06, 3.1301e-06, 6.5055e-06,\n",
       "        2.8007e-06, 2.0405e-06, 6.4594e-07, 2.3103e-06, 7.3336e-06, 8.2150e-07,\n",
       "        4.4605e-06, 8.9171e-06, 8.5903e-07, 3.0383e-06, 2.2894e-06, 1.1486e-06,\n",
       "        2.6119e-06, 5.4423e-06, 6.8656e-06, 5.3260e-06, 1.1824e-06, 3.0044e-03,\n",
       "        1.7067e-04, 9.9581e-04, 2.6673e-04, 2.0102e-05, 1.6491e-03, 3.7296e-04,\n",
       "        2.0319e-05, 2.0037e-05, 5.6762e-05, 3.1443e-04, 1.1289e-03, 1.6631e-04,\n",
       "        2.6962e-04, 1.0974e-05, 3.7288e-05, 1.3116e-03, 4.8098e-05, 4.0294e-06,\n",
       "        1.4166e-05, 1.4046e-04, 3.8318e-06, 4.6794e-05, 1.1825e-04, 1.9641e-04,\n",
       "        1.1030e-03, 1.0190e-05, 1.3713e-03, 5.4010e-05, 6.4413e-04, 2.5243e-04,\n",
       "        1.4384e-04, 1.5054e-05, 5.9337e-03, 1.9320e-03, 1.2878e-04, 9.1305e-06,\n",
       "        2.4289e-05, 2.2195e-05, 4.3131e-05, 5.4061e-04, 1.2365e-03, 2.1018e-04,\n",
       "        5.7232e-05, 1.0216e-04, 9.4730e-05, 2.6122e-05, 2.1716e-05, 1.1804e-05,\n",
       "        5.9479e-05, 8.3541e-04, 5.5342e-04, 2.1368e-05, 5.1965e-05, 9.1993e-05,\n",
       "        1.5841e-05, 8.6793e-05, 9.0378e-05, 3.5025e-04, 1.1869e-05, 2.5122e-05,\n",
       "        9.5700e-05, 2.3320e-04, 4.6439e-04, 2.7194e-05, 7.0144e-06, 1.0533e-04,\n",
       "        1.0433e-03, 6.0851e-02, 1.5540e-05, 2.5038e-04, 1.2024e-05, 2.3249e-04,\n",
       "        1.5962e-04, 7.5420e-05, 2.2754e-02, 3.5807e-04, 2.3481e-05, 3.2290e-05,\n",
       "        1.4101e-05, 5.7534e-05, 4.5521e-05, 5.1137e-05, 4.7621e-04, 2.0388e-02,\n",
       "        9.7790e-05, 3.9083e-05, 9.5814e-05, 1.3715e-03, 3.3358e-05, 1.1169e-04,\n",
       "        9.7178e-06, 4.5887e-05, 1.0715e-04, 4.4141e-06, 5.3903e-06, 1.0493e-04,\n",
       "        5.0500e-05, 2.7355e-04, 1.2894e-04, 1.4759e-05, 1.0018e-04, 2.6972e-04,\n",
       "        2.7550e-05, 4.2924e-06, 3.7960e-05, 1.5383e-05, 1.3792e-04, 1.1838e-05,\n",
       "        1.2261e-04, 5.2827e-04, 1.1339e-05, 6.2009e-04, 9.1760e-02, 3.7593e-04,\n",
       "        2.0827e-04, 4.5577e-05, 3.1228e-05, 1.2490e-04, 2.0410e-04, 3.4966e-05,\n",
       "        1.3943e-05, 4.0503e-05, 2.8369e-03, 3.0548e-05, 1.2664e-01, 2.2544e-03,\n",
       "        1.8602e-05, 7.1361e-05, 3.4372e-03, 2.0889e-05, 9.3029e-06, 2.7058e-05,\n",
       "        1.1193e-03, 2.4847e-03, 1.1900e-04, 3.0992e-06, 2.3204e-04, 4.3545e-04,\n",
       "        3.0057e-05, 3.1375e-05, 1.7046e-04, 1.0364e-04, 1.2838e-04, 4.5132e-05,\n",
       "        1.5012e-05, 2.4931e-05, 3.3660e-05, 1.0439e-05, 6.9587e-06, 7.9833e-03,\n",
       "        2.2559e-05, 2.1122e-04, 1.0623e-04, 7.4918e-03, 5.7268e-05, 2.4428e-04,\n",
       "        2.4061e-04, 9.4974e-06, 4.4398e-05, 1.6752e-05, 1.2339e-04, 1.3430e-04,\n",
       "        4.7461e-04, 3.2433e-05, 1.7457e-05, 1.4070e-05, 5.2262e-05, 1.0194e-03,\n",
       "        2.5304e-04, 1.4995e-04, 4.1739e-05, 1.1543e-05, 7.8809e-06, 3.1125e-03,\n",
       "        1.5269e-05, 1.8335e-05, 5.8126e-05, 3.8119e-04, 4.6827e-05, 1.0713e-06,\n",
       "        2.5486e-04, 2.2047e-05, 7.0145e-04, 1.0195e-04, 1.2437e-04, 9.8667e-06,\n",
       "        1.0745e-04, 9.5789e-05, 6.6764e-05, 2.3618e-05, 2.6608e-05, 4.0992e-05,\n",
       "        1.3113e-05, 7.3510e-05, 3.3694e-02, 2.2322e-04, 6.4641e-06, 4.1868e-03,\n",
       "        4.1453e-04, 6.9605e-03, 2.8581e-04, 2.3708e-04, 1.7711e-05, 2.6948e-04,\n",
       "        5.6411e-05, 1.1108e-05, 1.6906e-03, 5.5916e-03, 1.5162e-04, 1.9135e-05,\n",
       "        3.5307e-03, 1.7957e-04, 2.1802e-03, 1.7465e-05, 2.6447e-04, 3.7509e-05,\n",
       "        4.0188e-04, 2.4637e-05, 8.3973e-04, 1.5347e-05, 4.0508e-05, 3.3234e-05,\n",
       "        2.4780e-05, 5.7157e-04, 5.6880e-05, 5.5331e-03, 1.0325e-03, 9.8503e-05,\n",
       "        1.6139e-04, 1.8304e-05, 7.9882e-05, 5.9171e-05, 9.0424e-05, 1.7083e-03,\n",
       "        1.9040e-05, 7.3125e-06, 3.4733e-04, 1.3037e-04, 5.7904e-06, 8.7303e-04,\n",
       "        2.7022e-01, 9.3086e-05, 6.1600e-04, 1.0861e-04, 6.6660e-06, 1.5922e-04,\n",
       "        5.1927e-04, 3.7779e-05, 3.6206e-04, 8.2755e-05, 2.6482e-05, 4.2798e-03,\n",
       "        1.3162e-05, 2.2201e-03, 6.5656e-05, 1.5838e-05, 3.0631e-05, 1.0694e-04,\n",
       "        1.0335e-05, 4.0822e-05, 1.1396e-03, 9.0956e-05, 9.6460e-05, 6.1035e-06,\n",
       "        4.0701e-05, 4.1802e-04, 1.9467e-05, 7.6788e-05, 1.7322e-03, 8.8489e-05,\n",
       "        2.0623e-05, 1.9450e-05, 2.3841e-04, 2.6624e-06, 2.4036e-04, 1.6898e-04,\n",
       "        2.7772e-04, 3.5315e-03, 6.1095e-06, 1.5184e-05, 4.9963e-04, 2.5061e-04,\n",
       "        1.0669e-04, 1.4302e-03, 1.7895e-04, 7.2166e-06, 3.0211e-03, 5.2186e-04,\n",
       "        4.0198e-03, 8.1569e-05, 4.1997e-04, 4.2868e-04, 1.5224e-05, 1.0903e-04,\n",
       "        1.5528e-03, 1.2736e-05, 8.6195e-05, 1.7016e-06, 1.4681e-05, 8.6468e-05,\n",
       "        8.1773e-06, 5.9815e-05, 2.8512e-04, 1.2087e-03, 1.3629e-05, 4.7378e-05,\n",
       "        2.3082e-04, 6.8335e-05, 1.1659e-05, 1.4225e-04, 1.8820e-04, 3.1151e-04,\n",
       "        1.1161e-03, 3.6533e-05, 7.8492e-06, 7.9655e-05, 9.1194e-06, 2.0109e-05,\n",
       "        8.8088e-05, 1.0783e-03, 7.7752e-05, 2.5430e-04, 1.2084e-04, 3.7361e-05,\n",
       "        6.5759e-04, 1.4127e-04, 1.3922e-05, 6.4344e-05, 1.1821e-05, 2.2037e-04,\n",
       "        1.2352e-04, 9.9565e-05, 4.2205e-04, 3.1956e-04, 3.1270e-05, 5.8274e-05,\n",
       "        3.4997e-04, 1.4808e-05, 2.1173e-04, 3.8041e-05, 1.6639e-05, 1.1011e-03,\n",
       "        1.3619e-05, 1.8245e-03, 7.6890e-06, 4.3047e-05, 1.6131e-04, 5.6460e-04,\n",
       "        7.9267e-05, 1.1254e-04, 5.0281e-04, 1.8062e-04, 1.3044e-05, 2.6687e-05,\n",
       "        1.4311e-04, 7.0104e-06, 4.0497e-04, 1.3381e-02, 3.2328e-04, 1.9762e-03,\n",
       "        5.6691e-05, 2.8224e-05, 6.1743e-04, 2.3129e-04, 4.1130e-04, 1.1815e-04,\n",
       "        1.3249e-05, 4.6237e-05, 8.4253e-04, 9.5434e-05, 7.5864e-05, 1.1676e-03,\n",
       "        3.2712e-05, 6.3744e-04, 6.3913e-04, 1.5297e-04, 4.6522e-05, 1.5817e-04,\n",
       "        2.6154e-03, 1.3604e-04, 5.5548e-02, 3.7523e-05, 5.3065e-05, 8.4199e-05,\n",
       "        9.4694e-03, 2.3972e-04, 3.3633e-05, 1.0217e-02, 7.1065e-05, 8.2717e-06,\n",
       "        4.8108e-05, 7.4515e-05, 1.1744e-04, 2.4220e-04, 1.0203e-02, 2.1706e-04,\n",
       "        4.6567e-06, 2.0792e-04, 1.8651e-03, 1.8659e-05, 2.7286e-04, 3.2512e-05,\n",
       "        6.3020e-04, 6.4769e-05, 1.7709e-05, 1.6244e-03, 1.6411e-03, 3.7547e-03,\n",
       "        2.8998e-05, 2.2139e-05, 1.8737e-05, 1.1968e-03, 6.8055e-05, 5.1421e-06,\n",
       "        2.2034e-05, 6.0908e-04, 4.5783e-03, 1.1643e-05, 4.8262e-03, 7.7221e-05,\n",
       "        5.2132e-05, 1.9313e-04, 1.8837e-05, 3.4247e-04, 3.6190e-05, 1.0557e-05,\n",
       "        7.2709e-05, 2.8846e-05, 2.0241e-04, 1.2439e-04, 1.3968e-05, 1.7603e-05,\n",
       "        7.0030e-05, 1.7519e-04, 7.7805e-04, 1.6818e-05, 8.7188e-05, 7.5121e-05,\n",
       "        6.8766e-04, 7.2804e-06, 2.2318e-04, 2.0184e-04, 1.7865e-05, 1.2793e-04,\n",
       "        2.0943e-03, 8.8127e-06, 6.9923e-04, 5.9633e-04, 1.2380e-04, 8.8752e-06,\n",
       "        3.6010e-04, 3.1724e-04, 5.7690e-04, 1.1565e-04, 7.1228e-05, 9.7302e-05,\n",
       "        7.5390e-05, 6.0723e-06, 3.8103e-05, 1.9932e-05, 2.2858e-04, 1.5155e-04,\n",
       "        1.9049e-03, 2.4797e-05, 2.0104e-04, 2.6997e-04, 6.2993e-06, 9.2054e-05,\n",
       "        1.7811e-05, 5.0172e-05, 2.3398e-04, 1.0286e-04, 4.2340e-04, 2.7543e-03,\n",
       "        7.9294e-06, 3.6075e-05, 1.6830e-05, 1.3826e-05, 5.8568e-05, 1.8578e-04,\n",
       "        7.2756e-05, 1.3160e-04, 1.2282e-04, 6.9012e-06, 1.6145e-06, 9.0760e-05,\n",
       "        1.3734e-05, 5.5097e-05, 3.6085e-05, 1.0572e-04, 1.0621e-03, 3.1782e-05,\n",
       "        3.6527e-04, 5.3469e-04, 1.3534e-05, 2.0316e-03, 8.2597e-05, 5.3863e-05,\n",
       "        1.9202e-05, 4.4880e-04, 6.1706e-05, 4.1645e-04, 1.4259e-04, 2.3004e-03,\n",
       "        7.2589e-05, 1.0386e-04, 7.3267e-05, 7.1842e-05, 9.1503e-04, 6.0177e-05,\n",
       "        7.5583e-06, 1.3337e-05, 7.8399e-04, 9.8626e-04, 1.3711e-04, 3.5502e-05,\n",
       "        1.6269e-02, 6.7270e-04, 2.5295e-05, 5.9126e-05, 1.8694e-04, 2.1644e-03,\n",
       "        3.7070e-05, 1.9086e-05, 1.4999e-05, 5.4371e-06, 1.9635e-04, 1.0018e-04,\n",
       "        3.2492e-05, 2.6265e-05, 1.0423e-04, 3.1664e-05, 2.3472e-06, 1.1839e-04,\n",
       "        8.5444e-05, 8.5358e-06, 5.8904e-06, 2.4847e-05, 1.3756e-05, 5.9600e-05,\n",
       "        1.1354e-04, 1.4781e-05, 2.2574e-05, 8.2336e-07, 9.2116e-05, 2.0096e-05,\n",
       "        1.4517e-04, 1.5618e-05, 3.2229e-05, 5.4255e-04, 1.4657e-04, 8.6019e-06,\n",
       "        9.7833e-06, 5.9598e-05, 6.5475e-05, 1.0384e-04, 1.1666e-05, 1.6861e-05,\n",
       "        3.4292e-05, 2.5173e-04, 7.5333e-05, 2.4042e-05, 3.5404e-05, 2.7452e-05,\n",
       "        1.8483e-04, 4.2326e-05, 1.8424e-05, 1.1917e-04, 9.5680e-06, 2.3363e-05,\n",
       "        2.2402e-04, 7.6212e-06, 4.5601e-05, 1.9596e-05, 2.4821e-05, 1.0041e-04,\n",
       "        2.0047e-03, 4.9372e-05, 6.0205e-05, 1.4884e-05, 1.1589e-05, 6.1243e-06,\n",
       "        6.6789e-05, 1.3184e-04, 1.9673e-06, 8.5695e-05, 1.1833e-05, 1.0755e-04,\n",
       "        3.4025e-05, 1.3376e-05, 5.6937e-05, 5.7320e-04, 1.0788e-05, 7.2275e-05,\n",
       "        2.1063e-05, 7.0868e-05, 2.8692e-05, 1.2184e-04, 1.1364e-05, 2.7962e-05,\n",
       "        7.4151e-05, 5.9048e-06, 8.7985e-06, 1.5298e-05, 1.7904e-04, 1.1673e-04,\n",
       "        4.0347e-05, 1.7619e-05, 7.0614e-05, 1.5388e-05])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    targets = model(batch_img)\n",
    "is_it = torch.nn.functional.softmax(targets[0], dim=0)\n",
    "is_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f6db528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tench</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>goldfish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great white shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tiger shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hammerhead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>earthstar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>hen-of-the-woods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>bolete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>toilet tissue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "0                tench\n",
       "1             goldfish\n",
       "2    great white shark\n",
       "3          tiger shark\n",
       "4           hammerhead\n",
       "..                 ...\n",
       "995          earthstar\n",
       "996   hen-of-the-woods\n",
       "997             bolete\n",
       "998                ear\n",
       "999      toilet tissue\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "img_Classes = pd.read_csv('https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt', header=None)\n",
    "img_Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "499e5598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27% chance image is a Loafer\n",
      "12% chance image is a cowboy boot\n",
      "9% chance image is a clog\n",
      "6% chance image is a bow tie\n",
      "5% chance image is a running shoe\n"
     ]
    }
   ],
   "source": [
    "topk = 5\n",
    "prob , img_class_number = torch.topk(is_it,topk)\n",
    "for i in range(topk):\n",
    "    likelihood = prob[i].item()\n",
    "    class_name = img_Classes[0][int(img_class_number[i])]\n",
    "    print('{}% chance image is a {}'.format(int(likelihood*100), class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e3fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "755c4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "def benchmark(model, device='cuda' , input_shape=(4, 3, 224, 224), dtype='fp32', nwarmup=5, nruns=20):\n",
    "    input_data = torch.randn(input_shape)\n",
    "    input_data = input_data.to(device)\n",
    "        \n",
    "    print(\"Warm up ...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(nwarmup):\n",
    "            features = model(input_data)\n",
    "    #torch.cuda.synchronize() #Comment to avoid cuda compile error for torch\n",
    "    print(\"Start timing ...\")\n",
    "    timings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(1, nruns+1):\n",
    "            start_time = time.time()\n",
    "            features = model(input_data)\n",
    "            #torch.cuda.synchronize() #Comment to avoid cuda compile error for torch\n",
    "            end_time = time.time()\n",
    "            timings.append(end_time - start_time)\n",
    "            if i%10==0:\n",
    "                print('Iteration %d/%d, ave batch time %.2f ms'%(i, nruns, np.mean(timings)*1000))\n",
    "\n",
    "    print(\"Input shape:\", input_data.size())\n",
    "    print(\"Output features size:\", features.size())\n",
    "    print('Average batch time: %.2f ms'%(np.mean(timings)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07453411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/20, ave batch time 434.40 ms\n",
      "Iteration 20/20, ave batch time 453.25 ms\n",
      "Input shape: torch.Size([4, 3, 224, 224])\n",
      "Output features size: torch.Size([4, 1000])\n",
      "Average batch time: 453.25 ms\n"
     ]
    }
   ],
   "source": [
    "benchmark(model, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5faa54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbfc176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42149da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8948422f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
